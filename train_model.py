import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, precision_score
from sklearn.utils.class_weight import compute_sample_weight
import matplotlib.pyplot as plt
import seaborn as sns
import os
import joblib
from sklearn.preprocessing import StandardScaler

# í•œê¸€ í°íŠ¸ ì„¤ì •
try:
    plt.rcParams['font.family'] = 'Malgun Gothic'
except:
    plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False


class QuantMLModelTrainer:
    # â— [ìˆ˜ì •ëœ ë¶€ë¶„] data_pathì˜ íŒŒì¼ëª…ì„ ìµœì¢… ë²„ì „ì— ë§ê²Œ ìˆ˜ì •
    def __init__(self, data_path="./quantmo_data/ml_training_data_raw.parquet", model_save_path="./quantmo_data"):
        self.data_path = data_path
        self.model_save_path = model_save_path
        # â— [ìˆ˜ì •ëœ ë¶€ë¶„] 'OBV_Scaled'ë¥¼ 'OBV'ë¡œ ë³€ê²½í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
        self.feature_columns = [
            'RSI', 'Stoch_D', 'MACD_Hist', 'ADX',
            'Price_SMA200_Ratio', 'BB_Percent', 'MFI', 'OBV'
        ]
        self.model = None
        self.scaler = None
        print("QuantMLModelTrainerê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def load_data(self):
        if not os.path.exists(self.data_path):
            raise FileNotFoundError(f"{self.data_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        df = pd.read_parquet(self.data_path)
        df = df.sort_index()
        print(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ. ì´ {len(df)}ê°œì˜ ë°ì´í„°.")
        return df

    def split_and_scale_data(self, df):
        """ë°ì´í„°ë¥¼ ë¶„í• í•˜ê³ , í›ˆë ¨ ì„¸íŠ¸ ê¸°ì¤€ìœ¼ë¡œ Scalerë¥¼ í•™ìŠµ ë° ì ìš©í•©ë‹ˆë‹¤."""
        train_size = int(len(df) * 0.6)
        validation_size = int(len(df) * 0.2)
        train_df = df.iloc[:train_size]
        validation_df = df.iloc[train_size: train_size + validation_size]
        test_df = df.iloc[train_size + validation_size:]

        X_train_raw = train_df[self.feature_columns]
        y_train = train_df['Label']

        self.scaler = StandardScaler()
        X_train = self.scaler.fit_transform(X_train_raw)

        X_val = self.scaler.transform(validation_df[self.feature_columns])
        y_val = validation_df['Label']
        X_test = self.scaler.transform(test_df[self.feature_columns])
        y_test = test_df['Label']

        print("ë°ì´í„° ë¶„í•  ë° ìŠ¤ì¼€ì¼ë§ ì™„ë£Œ (60:20:20):")
        print(f" - í›ˆë ¨ìš©: {len(X_train)}ê°œ, ê²€ì¦ìš©: {len(X_val)}ê°œ, í…ŒìŠ¤íŠ¸ìš©: {len(X_test)}ê°œ")
        return X_train, y_train, X_val, y_val, X_test, y_test

    def train_model(self, X_train, y_train, X_val, y_val):
        """XGBoost ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤."""
        print("\nëª¨ë¸ í›ˆë ¨ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)
        self.model = xgb.XGBClassifier(
            objective='multi:softmax', num_class=3, n_estimators=1000,
            learning_rate=0.1, max_depth=5, use_label_encoder=False,
            eval_metric='mlogloss', random_state=42, tree_method='gpu_hist'
        )
        early_stopping_callback = xgb.callback.EarlyStopping(rounds=50, save_best=True)
        self.model.fit(X_train, y_train, sample_weight=sample_weights,
                       eval_set=[(X_val, y_val)], callbacks=[early_stopping_callback],
                       verbose=False)
        print("âœ… ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    def evaluate_model(self, X_test, y_test):
        """í›ˆë ¨ëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ í‰ê°€í•©ë‹ˆë‹¤."""
        print("\nëª¨ë¸ ì„±ëŠ¥ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
        y_pred = self.model.predict(X_test)

        precision_label_1 = precision_score(y_test, y_pred, labels=[1], average='micro')
        print("\n" + "=" * 50)
        print(f"ğŸ¯ í•µì‹¬ ì„±ê³¼: 'ë§¤ìˆ˜ ì„±ê³µ(Label 1)' ì˜ˆì¸¡ ì •ë°€ë„ = {precision_label_1:.2%}")
        print("=" * 50)

        print("\n[Classification Report]")
        print(classification_report(y_test, y_pred, target_names=['ë³´í•©(0)', 'ë§¤ìˆ˜ì„±ê³µ(1)', 'ë§¤ìˆ˜ì‹¤íŒ¨(2)']))

        print("\n[Confusion Matrix]")
        cm = confusion_matrix(y_test, y_pred)
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['ë³´í•©(0)', 'ë§¤ìˆ˜ì„±ê³µ(1)', 'ë§¤ìˆ˜ì‹¤íŒ¨(2)'],
                    yticklabels=['ë³´í•©(0)', 'ë§¤ìˆ˜ì„±ê³µ(1)', 'ë§¤ìˆ˜ì‹¤íŒ¨(2)'])
        plt.xlabel('Predicted Label');
        plt.ylabel('True Label');
        plt.title('Confusion Matrix')
        plt.show()

    def save_model_and_scaler(self):
        """í›ˆë ¨ëœ ëª¨ë¸ê³¼ Scalerë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        if self.model is None or self.scaler is None:
            print("ì €ì¥í•  ëª¨ë¸ ë˜ëŠ” ìŠ¤ì¼€ì¼ëŸ¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        if not os.path.exists(self.model_save_path):
            os.makedirs(self.model_save_path)

        model_path = os.path.join(self.model_save_path, 'xgb_model.json')
        self.model.save_model(model_path)
        print(f"\nâœ… í›ˆë ¨ëœ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {model_path}")

        scaler_path = os.path.join(self.model_save_path, 'scaler.joblib')
        joblib.dump(self.scaler, scaler_path)
        print(f"âœ… Scalerê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {scaler_path}")

    def run_training_pipeline(self):
        """ì „ì²´ í›ˆë ¨ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            df = self.load_data()
            X_train, y_train, X_val, y_val, X_test, y_test = self.split_and_scale_data(df)
            self.train_model(X_train, y_train, X_val, y_val)
            self.evaluate_model(X_test, y_test)
            self.save_model_and_scaler()
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == '__main__':
    trainer = QuantMLModelTrainer()
    trainer.run_training_pipeline()